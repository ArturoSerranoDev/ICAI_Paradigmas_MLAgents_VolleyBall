behaviors:
  Volleyball:
    trainer_type: ppo
    hyperparameters:
      batch_size: 4096  # Increased for faster processing
      buffer_size: 40960  # Increased in proportion to batch_size
      learning_rate: 0.0003  # Slightly increased for faster convergence
      beta: 0.005  # Increased to stabilize variance of policy
      epsilon: 0.2  # Increased for more exploration
      lambd: 0.95  # Increased for more bias towards recent samples
      num_epoch: 6  # Increased for more updates per sample
      learning_rate_schedule: constant
    network_settings:
      normalize: true
      hidden_units: 512  # Increased for more complex representations
      num_layers: 3  # Increased for deeper understanding
      vis_encode_type: simple
    reward_signals:
      extrinsic:
        gamma: 0.98  # Increased for longer term rewards
        strength: 1.0
    keep_checkpoints: 5
    max_steps: 50000000  # Increased for longer training
    time_horizon: 1000
    summary_freq: 10000  # Decreased for more frequent feedback
